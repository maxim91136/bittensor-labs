# Release v1.0.0-rc.5

Date: 2025-11-29

Summary
-------
This release focuses on operational robustness for Taostats collection, safer Cloudflare KV writes, and improved archival to R2. It introduces an append-capable Cloudflare Worker for taostats history, workflow hardening and naming consistency, and several bug/hardening fixes for CI scripts and environment parsing.

Highlights
----------
- Prefer server-side append for `taostats_history` via a dedicated Worker (`bittensor-taostats`).
- Publish workflow (`.github/workflows/publish-taostats.yml`) now validates the worker, does pre/post checks to ensure append succeeded, and only falls back to a merged PUT when explicitly allowed.
- Per-run archival of taostats snapshots to R2 (timestamped files) to preserve full history while keeping KV small.
- Renamed CI scripts and workflows to kebab-case and updated all references for consistency.
- Improved environment parsing across scripts to avoid ValueError on empty strings (`_int_env` helpers).
- Removed the prior daily consolidation flow (user requested) and simplified archival strategy.

Backend changes (major)
-----------------------
- Worker `functions/api/taostats_history.js`:
  - Supports GET (read history) and POST (append entries).
  - Optional write token support via environment binding `WRITE_TOKEN`.
  - Normalizes legacy single-object history values to an array, deduplicates entries by `_timestamp`, and bounds history to `HISTORY_MAX_ENTRIES`.
- Publish workflow `.github/workflows/publish-taostats.yml`:
  - Fetches Taostats and writes `taostats_latest.json` locally.
  - Attempts a POST to `CF_WORKER_URL` (if set) to append the latest entry server-side.
  - Validates pre/post history counts and will fail early if append did not increase the count (prevents silent overwrites).
  - Optional fallback: `ALLOW_KV_PUT_FALLBACK=true` will allow a safe client-side merge + PUT; default behavior is to fail rather than overwrite.
  - Installs `jq` for safe JSON merging and verification in workflows.
- R2 archival:
  - Per-run: each fetch creates a timestamped `taostats_entry-<TS>.json` and uploads it to R2 via `.github/scripts/backup-issuance-history-r2.py` (supports S3-compatible and Cloudflare HTTP fallback).
  - Scheduled backups: `backup-taostats-r2.yml` pulls the full `taostats_history` from KV on a schedule and uploads to R2 for long-term retention.

CI / Workflows
--------------
- `deploy-worker.yml`:
  - Generates `wrangler.toml` from secrets in CI, sets the worker name to `bittensor-taostats`, and optionally injects a custom route (`CF_WORKER_ROUTE`).
  - Post-deploy validation checks for expected API responses when `CF_WORKER_URL` is provided.
- `publish-taostats.yml`:
  - Prefers worker POST append and adds robust validation and controlled fallback behavior.
  - Ensures KV namespace accessibility before attempting writes.
- Backup workflows renamed to kebab-case for consistency (e.g., `backup-issuance-history-r2.yml`).

Scripts & Utilities
-------------------
- `.github/scripts/fetch_taostats.py`:
  - Collects Taostats data and writes `taostats_latest.json`.
  - Appends a compact entry to local `taostats_history.json` (bounded by `HISTORY_MAX_ENTRIES`).
- `.github/scripts/backup-issuance-history-r2.py`:
  - Uploads files to R2; supports S3-compatible credentials (boto3) and Cloudflare HTTP upload fallback.
- Added `_int_env` helper to robustly parse integer env vars and avoid crashes when secrets/environment values are empty strings.

Naming & documentation
----------------------
- Worker name changed from the legacy `bittensor-ath-atl` to `bittensor-taostats` to reflect the taostats responsibilities.
- README updated with instructions for Worker deployment, required repository secrets, and how to enable append vs. direct KV writes.

Security & Secrets
------------------
- Required repo secrets for full functionality:
  - `CF_API_TOKEN` (Cloudflare API token; used by Wrangler in CI and for KV/R2 operations)
  - `CF_ACCOUNT_ID` (Cloudflare account id)
  - `CF_METRICS_NAMESPACE_ID` (KV namespace id for `METRICS_KV` binding)
- Optional secrets:
  - `CF_WORKER_URL` (dev or custom domain URL for the worker; if set, the publish workflow POSTs to it)
  - `CF_WORKER_WRITE_TOKEN` (if the Worker is configured to require a write token)
  - `ENABLE_R2`, `R2_*` credentials for R2 uploads
  - `ALLOW_KV_PUT_FALLBACK` (set to `true` if you want the workflow to allow client-side merged PUT fallback)

Compatibility and migration notes
---------------------------------
- If your KV currently contains a legacy single-object `taostats_history` value (not an array), the Worker will coerce it to a single-element array and continue appends.
- If you prefer to normalize KV to compact snapshots only, consider running a one-time migration script that reads KV, maps objects to `{_timestamp, price, volume_24h}` and writes the normalized array back (the repository can be extended with a migration job if requested).

Testing & verification
----------------------
- Manual smoke checks and test commands are included in the README.
- Recommended verification steps after deploying RC5:
  1. Deploy worker via CI and confirm `wrangler` output includes the workers.dev URL.
  2. Set `CF_WORKER_URL` in repo secrets to the worker dev URL and run `publish-taostats` manually.
  3. Check Publish logs for `Posting to Worker at ...` and `Worker append finished successfully`.
  4. Confirm KV `taostats_history` length increased and the merged file is available via the worker GET endpoint.
  5. Verify R2 uploads in the R2 bucket (per-run snapshot files).

Next steps / Suggestions
-----------------------
- If you want stricter append-only behavior, keep `ALLOW_KV_PUT_FALLBACK` unset/`false` so the workflow fails instead of performing client-side PUTs.
- Consider normalizing stored history to compact snapshots in the Worker to keep KV lightweight and consistent.
- Add monitoring for KV size and R2 storage usage to avoid surprises.

Acknowledgements
----------------
Thanks to the team for testing the Worker and identifying the `bittensor-ath-atl` naming issue â€” that is resolved in this release.

---

Prepared by: Release tooling (CI) & maintainer edits

